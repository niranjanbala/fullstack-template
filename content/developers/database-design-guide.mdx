---
title: "Database Design & Optimization"
description: "Design efficient database schemas and optimize queries for performance. Master SQL and NoSQL database design, indexing, query optimization, and performance tuning techniques for high-performance applications."
category: "developers"
tags: ["database", "sql", "nosql", "postgresql", "mongodb", "optimization", "indexing"]
publishedAt: "2024-01-15"
difficulty: "intermediate"
externalLinks:
  - title: "PostgreSQL Documentation"
    url: "https://www.postgresql.org/docs/"
    description: "Official PostgreSQL documentation"
    category: "documentation"
  - title: "MongoDB Manual"
    url: "https://docs.mongodb.com/manual/"
    description: "Complete MongoDB documentation"
    category: "documentation"
  - title: "MySQL Documentation"
    url: "https://dev.mysql.com/doc/"
    description: "Official MySQL documentation"
    category: "documentation"
  - title: "Redis Documentation"
    url: "https://redis.io/documentation"
    description: "Redis in-memory database documentation"
    category: "documentation"
  - title: "Database Design Patterns"
    url: "https://martinfowler.com/articles/patterns-of-distributed-systems/"
    description: "Distributed database patterns by Martin Fowler"
    category: "patterns"
relatedGuides: ["backend-development-guide", "performance-optimization-guide", "microservices-guide"]
---

# Database Design & Optimization

Design efficient, scalable databases that power modern applications. Master SQL and NoSQL database design principles, indexing strategies, query optimization, and performance tuning techniques for high-traffic systems.

## Introduction

Database design is the foundation of application performance and scalability. This guide covers:

- **Schema Design**: Normalization, denormalization, and design patterns
- **SQL Optimization**: Query performance, indexing, and execution plans
- **NoSQL Strategies**: Document, key-value, and graph database design
- **Performance Tuning**: Connection pooling, caching, and monitoring
- **Scaling Techniques**: Sharding, replication, and distributed databases

<Callout type="info">
Proper database design and optimization can improve application performance by 100x and reduce infrastructure costs by 60%.
</Callout>

## SQL Database Design

### Normalization and Schema Design

Design efficient relational schemas with proper normalization:

```sql
-- Well-designed user management schema
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    name VARCHAR(100) NOT NULL,
    avatar_url TEXT,
    email_verified BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    deleted_at TIMESTAMP WITH TIME ZONE NULL
);

-- User profiles (1:1 relationship)
CREATE TABLE user_profiles (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    bio TEXT,
    location VARCHAR(100),
    website VARCHAR(255),
    birth_date DATE,
    phone VARCHAR(20),
    privacy_settings JSONB DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    
    UNIQUE(user_id)
);

-- Posts (1:many relationship)
CREATE TABLE posts (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    author_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    title VARCHAR(255) NOT NULL,
    content TEXT NOT NULL,
    excerpt TEXT,
    slug VARCHAR(255) UNIQUE NOT NULL,
    status VARCHAR(20) DEFAULT 'draft' CHECK (status IN ('draft', 'published', 'archived')),
    published_at TIMESTAMP WITH TIME ZONE,
    view_count INTEGER DEFAULT 0,
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    
    -- Ensure published posts have published_at
    CONSTRAINT published_posts_have_date CHECK (
        (status = 'published' AND published_at IS NOT NULL) OR 
        (status != 'published')
    )
);

-- Tags (many:many relationship)
CREATE TABLE tags (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(50) UNIQUE NOT NULL,
    slug VARCHAR(50) UNIQUE NOT NULL,
    description TEXT,
    color VARCHAR(7) DEFAULT '#3b82f6',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Post-tag junction table
CREATE TABLE post_tags (
    post_id UUID NOT NULL REFERENCES posts(id) ON DELETE CASCADE,
    tag_id UUID NOT NULL REFERENCES tags(id) ON DELETE CASCADE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    
    PRIMARY KEY (post_id, tag_id)
);

-- Comments (self-referencing hierarchy)
CREATE TABLE comments (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    post_id UUID NOT NULL REFERENCES posts(id) ON DELETE CASCADE,
    author_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    parent_id UUID REFERENCES comments(id) ON DELETE CASCADE,
    content TEXT NOT NULL,
    status VARCHAR(20) DEFAULT 'published' CHECK (status IN ('published', 'pending', 'spam', 'deleted')),
    upvotes INTEGER DEFAULT 0,
    downvotes INTEGER DEFAULT 0,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    
    -- Prevent self-referencing comments
    CONSTRAINT no_self_reference CHECK (id != parent_id)
);
```

### Advanced PostgreSQL Features

Leverage PostgreSQL's advanced capabilities:

```sql
-- JSONB for flexible data storage
ALTER TABLE users ADD COLUMN preferences JSONB DEFAULT '{}';

-- Add GIN index for JSONB queries
CREATE INDEX idx_users_preferences ON users USING GIN (preferences);

-- Query JSONB data efficiently
SELECT * FROM users 
WHERE preferences->>'theme' = 'dark'
AND preferences->'notifications'->>'email' = 'true';

-- Full-text search with tsvector
ALTER TABLE posts ADD COLUMN search_vector tsvector;

-- Update search vector with triggers
CREATE OR REPLACE FUNCTION update_search_vector() RETURNS TRIGGER AS $$
BEGIN
    NEW.search_vector := to_tsvector('english', COALESCE(NEW.title, '') || ' ' || COALESCE(NEW.content, ''));
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER posts_search_vector_update 
    BEFORE INSERT OR UPDATE ON posts
    FOR EACH ROW EXECUTE FUNCTION update_search_vector();

-- GIN index for full-text search
CREATE INDEX idx_posts_search ON posts USING GIN (search_vector);

-- Full-text search queries
SELECT posts.*, ts_rank(search_vector, query) AS rank
FROM posts, to_tsquery('english', 'database & optimization') query
WHERE search_vector @@ query
ORDER BY rank DESC;

-- Partial indexes for performance
CREATE INDEX idx_posts_published ON posts (published_at DESC) 
WHERE status = 'published';

CREATE INDEX idx_comments_pending ON comments (created_at) 
WHERE status = 'pending';

-- Composite indexes for complex queries
CREATE INDEX idx_posts_author_status ON posts (author_id, status, published_at DESC);
```

### Query Optimization

Optimize SQL queries for better performance:

```sql
-- Efficient pagination with cursor-based approach
-- Instead of OFFSET/LIMIT (inefficient for large datasets)
SELECT * FROM posts 
WHERE created_at < $1 
ORDER BY created_at DESC 
LIMIT 20;

-- Optimized JOIN queries
SELECT 
    p.id,
    p.title,
    p.published_at,
    u.name as author_name,
    u.avatar_url,
    COUNT(c.id) as comment_count
FROM posts p
JOIN users u ON p.author_id = u.id
LEFT JOIN comments c ON p.id = c.post_id AND c.status = 'published'
WHERE p.status = 'published'
GROUP BY p.id, p.title, p.published_at, u.name, u.avatar_url
ORDER BY p.published_at DESC
LIMIT 20;

-- Using CTEs for complex queries
WITH popular_posts AS (
    SELECT 
        p.id,
        p.title,
        p.view_count,
        p.published_at,
        u.name as author_name
    FROM posts p
    JOIN users u ON p.author_id = u.id
    WHERE p.status = 'published'
    AND p.published_at > NOW() - INTERVAL '30 days'
),
post_stats AS (
    SELECT 
        pp.id,
        pp.title,
        pp.view_count,
        pp.published_at,
        pp.author_name,
        COUNT(c.id) as comment_count,
        COUNT(DISTINCT pt.tag_id) as tag_count
    FROM popular_posts pp
    LEFT JOIN comments c ON pp.id = c.post_id AND c.status = 'published'
    LEFT JOIN post_tags pt ON pp.id = pt.post_id
    GROUP BY pp.id, pp.title, pp.view_count, pp.published_at, pp.author_name
)
SELECT * FROM post_stats
ORDER BY view_count DESC, comment_count DESC
LIMIT 10;
```

### Database Connection Management

Implement efficient connection pooling:

```javascript
// PostgreSQL connection pool with proper configuration
const { Pool } = require('pg');

const pool = new Pool({
  host: process.env.DB_HOST,
  port: process.env.DB_PORT,
  database: process.env.DB_NAME,
  user: process.env.DB_USER,
  password: process.env.DB_PASSWORD,
  
  // Connection pool settings
  min: 2,                    // Minimum connections
  max: 20,                   // Maximum connections
  idleTimeoutMillis: 30000,  // Close idle connections after 30s
  connectionTimeoutMillis: 2000, // Timeout for new connections
  
  // SSL configuration for production
  ssl: process.env.NODE_ENV === 'production' ? {
    rejectUnauthorized: false
  } : false
});

// Proper error handling and connection management
class DatabaseService {
  static async query(text, params) {
    const client = await pool.connect();
    try {
      const start = Date.now();
      const result = await client.query(text, params);
      const duration = Date.now() - start;
      
      // Log slow queries
      if (duration > 1000) {
        console.warn(`Slow query detected: ${duration}ms`, { text, params });
      }
      
      return result;
    } catch (error) {
      console.error('Database query error:', error);
      throw error;
    } finally {
      client.release();
    }
  }

  static async transaction(callback) {
    const client = await pool.connect();
    try {
      await client.query('BEGIN');
      const result = await callback(client);
      await client.query('COMMIT');
      return result;
    } catch (error) {
      await client.query('ROLLBACK');
      throw error;
    } finally {
      client.release();
    }
  }
}

// Usage example
const createUserWithProfile = async (userData, profileData) => {
  return DatabaseService.transaction(async (client) => {
    // Create user
    const userResult = await client.query(
      'INSERT INTO users (email, name, password_hash) VALUES ($1, $2, $3) RETURNING *',
      [userData.email, userData.name, userData.passwordHash]
    );
    
    const user = userResult.rows[0];
    
    // Create profile
    const profileResult = await client.query(
      'INSERT INTO user_profiles (user_id, bio, location) VALUES ($1, $2, $3) RETURNING *',
      [user.id, profileData.bio, profileData.location]
    );
    
    return {
      user,
      profile: profileResult.rows[0]
    };
  });
};
```

## NoSQL Database Design

### MongoDB Document Design

Design efficient MongoDB schemas:

```javascript
// User document with embedded and referenced data
const userSchema = {
  _id: ObjectId,
  email: String,
  name: String,
  passwordHash: String,
  profile: {
    bio: String,
    location: String,
    avatar: String,
    socialLinks: {
      twitter: String,
      linkedin: String,
      github: String
    }
  },
  preferences: {
    theme: String,
    notifications: {
      email: Boolean,
      push: Boolean,
      newsletter: Boolean
    },
    privacy: {
      showEmail: Boolean,
      showLocation: Boolean
    }
  },
  stats: {
    postCount: Number,
    followerCount: Number,
    followingCount: Number,
    lastLoginAt: Date
  },
  createdAt: Date,
  updatedAt: Date
};

// Post document with denormalized author info
const postSchema = {
  _id: ObjectId,
  title: String,
  content: String,
  excerpt: String,
  slug: String,
  
  // Denormalized author data for read performance
  author: {
    _id: ObjectId,
    name: String,
    avatar: String
  },
  
  // Embedded tags for better performance
  tags: [String],
  
  // Embedded comments for small numbers
  comments: [{
    _id: ObjectId,
    authorId: ObjectId,
    authorName: String,
    content: String,
    createdAt: Date,
    replies: [{
      _id: ObjectId,
      authorId: ObjectId,
      authorName: String,
      content: String,
      createdAt: Date
    }]
  }],
  
  status: String,
  publishedAt: Date,
  viewCount: Number,
  likeCount: Number,
  shareCount: Number,
  
  // For full-text search
  searchKeywords: [String],
  
  createdAt: Date,
  updatedAt: Date
};

// MongoDB indexes for performance
db.users.createIndex({ email: 1 }, { unique: true });
db.users.createIndex({ "profile.location": 1 });
db.users.createIndex({ createdAt: -1 });

db.posts.createIndex({ slug: 1 }, { unique: true });
db.posts.createIndex({ "author._id": 1, publishedAt: -1 });
db.posts.createIndex({ tags: 1 });
db.posts.createIndex({ status: 1, publishedAt: -1 });

// Compound indexes for complex queries
db.posts.createIndex({ 
  status: 1, 
  publishedAt: -1, 
  "author._id": 1 
});

// Text index for full-text search
db.posts.createIndex({ 
  title: "text", 
  content: "text", 
  searchKeywords: "text" 
});

// Partial indexes for specific use cases
db.posts.createIndex(
  { publishedAt: -1 },
  { partialFilterExpression: { status: "published" } }
);
```

### MongoDB Query Optimization

Optimize MongoDB queries for better performance:

```javascript
// Efficient aggregation pipeline
const getPopularPosts = async (limit = 10) => {
  return await db.posts.aggregate([
    // Match published posts from last 30 days
    {
      $match: {
        status: "published",
        publishedAt: { $gte: new Date(Date.now() - 30 * 24 * 60 * 60 * 1000) }
      }
    },
    
    // Add computed fields
    {
      $addFields: {
        score: {
          $add: [
            "$viewCount",
            { $multiply: ["$likeCount", 2] },
            { $multiply: ["$shareCount", 3] }
          ]
        }
      }
    },
    
    // Sort by score
    { $sort: { score: -1 } },
    
    // Limit results
    { $limit: limit },
    
    // Project only needed fields
    {
      $project: {
        title: 1,
        excerpt: 1,
        slug: 1,
        author: 1,
        tags: 1,
        publishedAt: 1,
        viewCount: 1,
        likeCount: 1,
        shareCount: 1,
        score: 1
      }
    }
  ]);
};

// Optimized pagination with skip/limit alternatives
const getPaginatedPosts = async (lastId = null, limit = 20) => {
  const query = { status: "published" };
  
  // Use cursor-based pagination for better performance
  if (lastId) {
    query._id = { $lt: ObjectId(lastId) };
  }
  
  return await db.posts.find(query)
    .sort({ _id: -1 })
    .limit(limit)
    .toArray();
};

// Efficient user lookup with populated data
const getUserWithPosts = async (userId) => {
  return await db.users.aggregate([
    { $match: { _id: ObjectId(userId) } },
    
    // Lookup user's posts
    {
      $lookup: {
        from: "posts",
        let: { userId: "$_id" },
        pipeline: [
          { $match: { 
            $expr: { $eq: ["$author._id", "$$userId"] },
            status: "published"
          }},
          { $sort: { publishedAt: -1 } },
          { $limit: 10 },
          { $project: { title: 1, slug: 1, publishedAt: 1, viewCount: 1 } }
        ],
        as: "recentPosts"
      }
    },
    
    // Project final result
    {
      $project: {
        passwordHash: 0,
        "preferences.notifications": 0
      }
    }
  ]);
};
```

## Database Performance Monitoring

### PostgreSQL Performance Analysis

```sql
-- Monitor slow queries
SELECT 
    query,
    calls,
    total_time,
    mean_time,
    max_time,
    stddev_time,
    (total_time/calls) as avg_time_ms
FROM pg_stat_statements
WHERE calls > 100
ORDER BY total_time DESC
LIMIT 20;

-- Check index usage
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes
WHERE idx_scan = 0
ORDER BY schemaname, tablename;

-- Monitor table statistics
SELECT 
    schemaname,
    tablename,
    n_tup_ins,
    n_tup_upd,
    n_tup_del,
    n_live_tup,
    n_dead_tup,
    last_vacuum,
    last_autovacuum,
    last_analyze,
    last_autoanalyze
FROM pg_stat_user_tables
ORDER BY n_dead_tup DESC;

-- Connection monitoring
SELECT 
    datname,
    usename,
    application_name,
    client_addr,
    state,
    query_start,
    state_change,
    waiting,
    query
FROM pg_stat_activity
WHERE state != 'idle'
ORDER BY query_start;
```

### MongoDB Performance Monitoring

```javascript
// Monitor MongoDB performance
const getDbStats = async () => {
  const stats = await db.stats();
  const serverStatus = await db.serverStatus();
  
  return {
    collections: stats.collections,
    dataSize: stats.dataSize,
    indexSize: stats.indexSize,
    avgObjSize: stats.avgObjSize,
    connections: serverStatus.connections,
    opcounters: serverStatus.opcounters,
    wiredTiger: serverStatus.wiredTiger?.cache
  };
};

// Profile slow operations
db.setProfilingLevel(1, { slowms: 100 });

// Analyze profiling data
db.system.profile.find().sort({ ts: -1 }).limit(10).pretty();

// Check index usage
db.posts.aggregate([
  { $indexStats: {} },
  { $sort: { "accesses.ops": -1 } }
]);
```

## Caching Strategies

### Redis Integration

```javascript
// Redis caching layer
const redis = require('redis');
const client = redis.createClient({
  host: process.env.REDIS_HOST,
  port: process.env.REDIS_PORT,
  password: process.env.REDIS_PASSWORD,
  db: 0,
  retry_strategy: (options) => {
    if (options.error && options.error.code === 'ECONNREFUSED') {
      return new Error('Redis server connection refused');
    }
    if (options.total_retry_time > 1000 * 60 * 60) {
      return new Error('Redis retry time exhausted');
    }
    if (options.attempt > 10) {
      return undefined;
    }
    return Math.min(options.attempt * 100, 3000);
  }
});

class CacheService {
  static async get(key) {
    try {
      const value = await client.get(key);
      return value ? JSON.parse(value) : null;
    } catch (error) {
      console.error('Cache get error:', error);
      return null;
    }
  }

  static async set(key, value, ttl = 3600) {
    try {
      await client.setex(key, ttl, JSON.stringify(value));
    } catch (error) {
      console.error('Cache set error:', error);
    }
  }

  static async del(key) {
    try {
      await client.del(key);
    } catch (error) {
      console.error('Cache delete error:', error);
    }
  }

  static async getOrSet(key, fetcher, ttl = 3600) {
    let value = await this.get(key);
    if (value === null) {
      value = await fetcher();
      await this.set(key, value, ttl);
    }
    return value;
  }
}

// Usage in data access layer
const getUserPosts = async (userId) => {
  const cacheKey = `user:${userId}:posts`;
  
  return await CacheService.getOrSet(
    cacheKey,
    async () => {
      const posts = await db.posts.find({ 
        "author._id": ObjectId(userId),
        status: "published"
      }).sort({ publishedAt: -1 }).limit(10).toArray();
      
      return posts;
    },
    1800 // 30 minutes
  );
};
```

## Database Scaling Strategies

### Read Replicas

```javascript
// Multiple database connections for read scaling
const { Pool } = require('pg');

const masterPool = new Pool({
  connectionString: process.env.DATABASE_URL,
  max: 20
});

const replicaPool = new Pool({
  connectionString: process.env.DATABASE_READ_URL,
  max: 30
});

class DatabaseRouter {
  static async write(query, params) {
    return await masterPool.query(query, params);
  }

  static async read(query, params) {
    try {
      return await replicaPool.query(query, params);
    } catch (error) {
      // Fallback to master if replica fails
      console.warn('Read replica failed, falling back to master');
      return await masterPool.query(query, params);
    }
  }
}
```

### Sharding Strategy

```javascript
// MongoDB sharding configuration
const getShardedConnection = (shardKey) => {
  const shard = Math.abs(shardKey.hashCode()) % 3;
  return mongoClients[shard];
};

const getUserShard = (userId) => {
  return getShardedConnection(userId.toString());
};

// Sharded operations
const createUser = async (userData) => {
  const userId = new ObjectId();
  const shard = getUserShard(userId);
  
  return await shard.db('users').collection('users').insertOne({
    _id: userId,
    ...userData
  });
};
```

## Our Complete Database Methodology

<GitHubShowcase 
  repo="vimasa-consulting/database-optimization-framework"
  description="Explore our comprehensive database optimization framework with schema design patterns, query optimization techniques, and monitoring tools used in systems processing 1B+ queries daily."
/>

## Production Database Checklist

Before deploying to production:

- [ ] **Schema Design**: Normalized design with appropriate denormalization
- [ ] **Indexing Strategy**: Indexes for all query patterns without over-indexing
- [ ] **Query Optimization**: All queries tested for performance
- [ ] **Connection Pooling**: Proper connection management and pooling
- [ ] **Monitoring**: Query performance and resource usage monitoring
- [ ] **Backup Strategy**: Automated backups with tested recovery procedures
- [ ] **Security**: Proper authentication, authorization, and encryption
- [ ] **Scaling Plan**: Read replicas, sharding, or clustering as needed
- [ ] **Maintenance**: Regular VACUUM, ANALYZE, and optimization tasks
- [ ] **Documentation**: Schema documentation and query guides

<Callout type="success">
Proper database design and optimization can improve performance by 100x while reducing costs by 60%.
</Callout>

## External Resources for Continued Learning

- **[PostgreSQL Documentation](https://www.postgresql.org/docs/)**: Official PostgreSQL documentation
- **[MongoDB Manual](https://docs.mongodb.com/manual/)**: Complete MongoDB documentation
- **[MySQL Documentation](https://dev.mysql.com/doc/)**: Official MySQL documentation
- **[Redis Documentation](https://redis.io/documentation)**: Redis in-memory database documentation
- **[Database Design Patterns](https://martinfowler.com/articles/patterns-of-distributed-systems/)**: Distributed database patterns by Martin Fowler

## Conclusion

Database design and optimization are critical for application performance and scalability. By understanding both SQL and NoSQL design patterns, implementing proper indexing strategies, and monitoring performance, you can build databases that scale efficiently and perform reliably under load.

The key is to match your database choice and design to your specific use case, whether that's ACID compliance for financial data or flexible schema for content management systems.

---

*This guide is part of our comprehensive technical education platform. Explore our [database optimization methodology](https://github.com/vimasa-consulting/database-optimization-framework) for more production-ready practices.* 